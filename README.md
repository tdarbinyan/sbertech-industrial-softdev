# sbertech-industrial-softdev

Решения домашних заданий курса "Практикум по промышленной разработке программного обеспечения" кафедры "Банковских информационных технологий (Сбертех)"

***

### **Домашнее задание 1: Развёртывание распределённой системы логирования и хранения с резервным копированием**

1. **Создать пользовательское веб-приложение (API)**  
   Приложение должно реализовать следующие REST-эндпоинты:
   - `GET /` — возвращает строку `"Welcome to the custom app"`
   - `GET /status` — возвращает JSON `{"status": "ok"}`
   - `POST /log` — принимает JSON `{"message": "some log"}` и записывает его в файл `/app/logs/app.log`
   - `GET /logs` — возвращает содержимое файла `/app/logs/app.log`

   Приложение должно:
   - Писать логи в `/app/logs/app.log`
   - Использовать конфигурационные параметры (например, уровень логирования, порт, заголовок приветствия) из ConfigMap

2. **Развернуть приложение как Pod для начального теста**
   - Написать Dockerfile для приложения
   - Создать Pod, монтирующий:
      - `emptyDir` volume в `/app/logs`
      - ConfigMap с настройками в `/app/config` (или через переменные окружения)

3. **Развернуть приложение как Deployment**
   - Создать Deployment с 3 репликами
   - Настроить монтирование `emptyDir` для логов
   - Обновить Deployment, чтобы изменения в ConfigMap автоматически применялись
   - Проверить через Service и `kubectl port-forward`, что API работает

4. **Создать Service для балансировки нагрузки**
   - ClusterIP-сервис, направляющий трафик на поды приложения
   - Проверить: `curl http://<service-name>/logs` и `curl -X POST http://<service-name>/log -d '{"message": "test"}'`
   - Убедиться, что запросы распределяются между подами

5. **Развернуть DaemonSet с log-agent**
   - DaemonSet должен:
      - Быть запущен на каждом узле
      - Собирать логи приложения из подов (через `hostPath` или `emptyDir`, при наличии доступа)
      - Перенаправлять логи во stdout или сохранять локально на узле
   - Проверить, что `kubectl logs <log-agent-pod>` содержит записи из `app.log`

6. **Развернуть CronJob для архивирования логов**
   - CronJob должен запускаться раз в 10 минут
   - Команда: `tar -czf /tmp/app-logs-<timestamp>.tar.gz /app/logs/`
   - Логи берутся с сервисов приложения через HTTP API `/logs` (например, `curl`) или из общей директории, если доступна
   - Результат сохраняется в контейнере в `/tmp` (внутри пода CronJob)

7. **Создать единый bash-скрипт `deploy.sh` для автоматического развёртывания всей системы**
   - Скрипт должен:
      - Создавать все необходимые **ConfigMap**, **Pod**, **Deployment**, **Service**, **DaemonSet**, **StatefulSet**, **CronJob** и другие объекты
      - Использовать команды `kubectl apply -f` с заранее подготовленными YAML-файлами
      - Ожидать готовности ключевых компонентов
   - В **README.md** проекта добавьте команду для запуска скрипта из терминала

***

### **Домашнее задание 2: Добавление Istio в существующую Kubernetes-систему**

#### **1. Настроить Istio Gateway и обеспечить внешний доступ**

* Настройте объект `Gateway`, принимающий HTTP-трафик на порт 80.
* Настройте `VirtualService`, который подключён к этому Gateway.

#### **2. Настроить маршруты в VirtualService**

Создайте объект `VirtualService`, который:

* Обрабатывает все внешние запросы, поступающие через Gateway.
* Делает маршрутизацию на основное приложение
* Все неизвестные маршруты (например, `/wrong`) должны возвращать 404 ошибку

#### **3. Настроить DestinationRule для управления соединениями**

Для каждого сервиса, на который маршрутизируется трафик (например, `app-service`, `log-service`), настройте объект `DestinationRule` со следующими параметрами:

* Балансировка нагрузки:

    * используйте алгоритм `LEAST_CONN`, чтобы трафик направлялся туда, где меньше всего текущих подключений.
* Ограничение соединений:

    * максимум 3 одновременных TCP-соединений
    * максимум 5 ожидающих HTTP-запросов
* Включите защищённую межсервисную коммуникацию внутри mesh-а (`ISTIO_MUTUAL` TLS-режим)

#### **4. Настроить отказоустойчивость и политику доставки**

Для маршрута `POST /log` (в VirtualService) реализуйте поведение при сбоях:

* Добавьте искусственную задержку ответа — 2 секунды.
* Установите общий таймаут — 1 секунда (чтобы запрос завершался с ошибкой по таймауту).
* Разрешите повторные попытки — до 2 попыток в случае неудачи.

### **Ожидаемый результат**

* Все конфигурации (`Gateway`, `VirtualService`, `DestinationRule`) должны быть оформлены в отдельных YAML-файлах.
* bash-скрипт `deploy.sh` из предыдущего задания должен быть модифицирован и, помимо, применения новых манифестов, должен предварительно настроить istio service mesh в кластере

***

### **Домашнее задание 3: Добавление мониторинга через Prometheus**

#### **1. Настроить Prometheus для сбора метрик**

* Разверните Prometheus либо вручную, либо через официальный Helm-чарт `prometheus-community/kube-prometheus-stack`.
* Убедитесь, что Prometheus может:

  * собирать метрики с подов, содержащих **Envoy proxy** (через Istio)
  * автоматически обнаруживать сервисы внутри кластера через `kubernetes_sd_configs`
* Проверьте, что метрики Istio (например, `istio_requests_total`, `istio_request_duration_seconds`) доступны в интерфейсе Prometheus.

#### **2. Добавить метрики в пользовательское приложение**

* Модифицируйте приложение так, чтобы оно экспортировало метрики в формате Prometheus (например, через `/metrics`). Метрики должны включать:
  * общее количество вызовов `/log`
  * успешные и неуспешные попытки логирования
  * среднее время обработки запроса
* Используйте библиотеку для метрик на выбранном языке .

#### **3. Обеспечить сбор метрик Prometheus из приложения**

* Настройте `ServiceMonitor` или `PodMonitor`, если используется kube-prometheus-stack.
  Альтернативно — добавьте `scrape_configs` вручную, если вы используете свой Prometheus.
* Проверьте, что Prometheus может собирать метрики из `/metrics` endpoint-а приложения.
* Настройте label-селекторы для обнаружения только нужных подов.

### **Ожидаемый результат**

* Скрипт `deploy.sh` автоматически разворачивает все необходимое